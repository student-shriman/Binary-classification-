{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eQgXgXqmVTKd"
      },
      "outputs": [],
      "source": [
        "##  Importing some modules\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tppYW3y-VTKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d2f689-cb10-4c91-8349-70f0b8b8e52f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  786M  100  786M    0     0   146M      0  0:00:05  0:00:05 --:--:--  165M\n",
            " CDLA-Permissive-2.0.pdf      PetImages        sample_data\n",
            " kagglecatsanddogs_5340.zip  'readme[1].txt'\n"
          ]
        }
      ],
      "source": [
        "##  Downloading the Cats-Dogs image dataset and unzip ..\n",
        "!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
        "!unzip -q kagglecatsanddogs_5340.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zIZsLG-VTKf"
      },
      "source": [
        "Now we have a `PetImages` folder which contain two subfolders, `Cat` and `Dog`. Each\n",
        " subfolder contains image files for each category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LNtKM4JKVTKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b27ff2b1-f562-486b-bee4-fab2642d4efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat  Dog\n"
          ]
        }
      ],
      "source": [
        "##  Lising the contents of downloaded Dataset ..\n",
        "!ls PetImages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cJcKQti2VTKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871c2190-bfcd-47cb-c058-7edcffb92dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted 1590 images\n"
          ]
        }
      ],
      "source": [
        "##  filtering out some corrupted images\n",
        "num_skipped = 0\n",
        "for folder_name in (\"Cat\", \"Dog\"):\n",
        "    folder_path = os.path.join(\"PetImages\", folder_name)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            fobj = open(fpath, \"rb\")\n",
        "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
        "        finally:\n",
        "            fobj.close()\n",
        "\n",
        "        if not is_jfif:\n",
        "            num_skipped += 1\n",
        "            # Delete corrupted image\n",
        "            os.remove(fpath)\n",
        "\n",
        "print(\"Deleted %d images\" % num_skipped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7TALJ4QVTKh"
      },
      "source": [
        "## Generate a `Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m-5BrP27VTKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc94c2f9-7642-45d3-b417-4d8d32469d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 23410 files belonging to 2 classes.\n",
            "Using 18728 files for training.\n",
            "Found 23410 files belonging to 2 classes.\n",
            "Using 4682 files for validation.\n",
            " Image array  tf.Tensor(\n",
            "[[[122.903595 154.41476  132.18164 ]\n",
            "  [138.1098   171.8967   144.64069 ]\n",
            "  [109.009    132.17557  101.158615]\n",
            "  ...\n",
            "  [130.84973  142.151    120.45679 ]\n",
            "  [161.49414  171.26353  154.47592 ]\n",
            "  [117.85329  116.24391  105.15016 ]]\n",
            "\n",
            " [[133.45996  163.75133  142.31194 ]\n",
            "  [134.51598  155.44455  130.5874  ]\n",
            "  [ 92.39453   92.27992   66.62989 ]\n",
            "  ...\n",
            "  [129.36975  138.98271  121.84741 ]\n",
            "  [113.414246 124.78479   99.66413 ]\n",
            "  [135.6225   135.10687  108.65375 ]]\n",
            "\n",
            " [[ 98.29597  123.90311   98.328545]\n",
            "  [ 95.53948  105.63749   81.19922 ]\n",
            "  [106.74442   98.06578   76.06578 ]\n",
            "  ...\n",
            "  [146.60254  147.8746   133.50241 ]\n",
            "  [135.16428  134.81732  117.16701 ]\n",
            "  [ 91.548355  89.173355  74.829605]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[160.38916  139.22446  120.40576 ]\n",
            "  [118.55469  107.240166  92.77637 ]\n",
            "  [ 78.851494  82.971954  67.88044 ]\n",
            "  ...\n",
            "  [ 81.83097   82.85533   49.286346]\n",
            "  [146.70847  162.1705   117.98573 ]\n",
            "  [150.4015   175.87025  120.72963 ]]\n",
            "\n",
            " [[141.73235  129.08502  103.34208 ]\n",
            "  [108.748535 107.9707    82.84885 ]\n",
            "  [137.52197  152.39474  125.79702 ]\n",
            "  ...\n",
            "  [113.34854  113.73122   92.48396 ]\n",
            "  [ 60.864025  62.844063  35.21238 ]\n",
            "  [ 95.40575   99.40575   64.7495  ]]\n",
            "\n",
            " [[102.75635   91.956894  70.01305 ]\n",
            "  [116.710175 114.11698   86.80874 ]\n",
            "  [128.93967  136.3093   107.19713 ]\n",
            "  ...\n",
            "  [107.02758  121.71686   87.05481 ]\n",
            "  [117.22508  128.17633   94.45242 ]\n",
            "  [114.8828   124.39842   86.4453  ]]], shape=(224, 224, 3), dtype=float32)\n",
            "\n",
            "\n",
            "Image label  :  tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "##  Generating dataset ..\n",
        "\n",
        "image_size = (224, 224)\n",
        "batch_size = 64\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\"PetImages\", validation_split=0.2, subset=\"training\", seed=1337, image_size=image_size, batch_size=batch_size,)\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\"PetImages\", validation_split=0.2,  subset=\"validation\",  seed=1337, image_size=image_size, batch_size=batch_size,)\n",
        "\n",
        "##  Getting the 1st record from dataset of batch_size 'n'\n",
        "records = []\n",
        "for i in train_ds:\n",
        "  records.append(i)\n",
        "img_arr = records[0][0][0]\n",
        "img_label = records[0][1][0]\n",
        "\n",
        "print (\" Image array \" , img_arr)\n",
        "print ('\\n')\n",
        "print (\"Image label  : \", img_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I4R7cHuUVTKh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "fe4d03a9-5e9f-4105-dc37-bb91e1f3fd5d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a7d2468ebe45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 0 - cat,  1 - Dog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "##  Visualizing some images from dataset ..\n",
        "# 0 - cat,  1 - Dog\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVBX_ODIVTKi"
      },
      "outputs": [],
      "source": [
        "##  Data augmentation \n",
        "\n",
        "data_augmentation = keras.Sequential([layers.RandomFlip(\"horizontal\"), \n",
        "                                      layers.RandomRotation(0.1),\n",
        "                                      layers.RandomBrightness(0.3),\n",
        "                                      layers.RandomContrast(0.4),\n",
        "                                      layers.RandomWidth(0.2)])\n",
        "                                     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTRoX8C-VTKi"
      },
      "source": [
        "Let's visualize what the augmented samples look like, by applying `data_augmentation`\n",
        "repeatedly to the first image in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VX73gC1VTKi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLRxgG5MVTKi"
      },
      "source": [
        "## Standardizing the data\n",
        "\n",
        "Our image are already in a standard size (180x180), as they are being yielded as\n",
        "contiguous `float32` batches by our dataset. However, their RGB channel values are in\n",
        "the `[0, 255]` range. This is not ideal for a neural network;\n",
        "in general you should seek to make your input values small. Here, we will\n",
        "standardize values to be in the `[0, 1]` by using a `Rescaling` layer at the start of\n",
        "our model.\n",
        "\n",
        "## Two options to preprocess the data\n",
        "\n",
        "There are two ways you could be using the `data_augmentation` preprocessor:\n",
        "\n",
        "**Option 1: Make it part of the model**, like this:\n",
        "\n",
        "```python\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "...  # Rest of the model\n",
        "```\n",
        "\n",
        "With this option, your data augmentation will happen *on device*, synchronously\n",
        "with the rest of the model execution, meaning that it will benefit from GPU\n",
        "acceleration.\n",
        "\n",
        "Note that data augmentation is inactive at test time, so the input samples will only be\n",
        "augmented during `fit()`, not when calling `evaluate()` or `predict()`.\n",
        "\n",
        "If you're training on GPU, this may be a good option.\n",
        "\n",
        "**Option 2: apply it to the dataset**, so as to obtain a dataset that yields batches of\n",
        "augmented images, like this:\n",
        "\n",
        "```python\n",
        "augmented_train_ds = train_ds.map(\n",
        "    lambda x, y: (data_augmentation(x, training=True), y))\n",
        "```\n",
        "\n",
        "With this option, your data augmentation will happen **on CPU**, asynchronously, and will\n",
        "be buffered before going into the model.\n",
        "\n",
        "If you're training on CPU, this is the better option, since it makes data augmentation\n",
        "asynchronous and non-blocking.\n",
        "\n",
        "In our case, we'll go with the second option. If you're not sure\n",
        "which one to pick, this second option (asynchronous preprocessing) is always a solid choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf4caOY0VTKj"
      },
      "outputs": [],
      "source": [
        "## Configure the dataset for performance\n",
        "# Let's make sure to use buffered prefetching so we can yield data from disk without having I/O becoming blocking ..\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=64)\n",
        "val_ds = val_ds.prefetch(buffer_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwopxm0vVTKj"
      },
      "source": [
        "## Build a model\n",
        "\n",
        "We'll build a small version of the Xception network. We haven't particularly tried to\n",
        "optimize the architecture; if you want to do a systematic search for the best model\n",
        " configuration, consider using\n",
        "[KerasTuner](https://github.com/keras-team/keras-tuner).\n",
        "\n",
        "Note that:\n",
        "\n",
        "- We start the model with the `data_augmentation` preprocessor, followed by a\n",
        " `Rescaling` layer.\n",
        "- We include a `Dropout` layer before the final classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bJ_TCeXVTKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed8e5d1-6c60-4218-8508-693f2310ac9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 224, None, 3  0           ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 224, None, 3  0           ['sequential[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 112, None, 3  896         ['rescaling[0][0]']              \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 112, None, 3  128        ['conv2d[0][0]']                 \n",
            " alization)                     2)                                                                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 112, None, 3  0           ['batch_normalization[0][0]']    \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 112, None, 6  18496       ['activation[0][0]']             \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 112, None, 6  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   4)                                                                \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 112, None, 6  0           ['batch_normalization_1[0][0]']  \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 112, None, 6  0           ['activation_1[0][0]']           \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d (SeparableCon  (None, 112, None, 1  8896       ['activation_2[0][0]']           \n",
            " v2D)                           28)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 112, None, 1  512        ['separable_conv2d[0][0]']       \n",
            " rmalization)                   28)                                                               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 112, None, 1  0           ['batch_normalization_2[0][0]']  \n",
            "                                28)                                                               \n",
            "                                                                                                  \n",
            " separable_conv2d_1 (SeparableC  (None, 112, None, 1  17664      ['activation_3[0][0]']           \n",
            " onv2D)                         28)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 112, None, 1  512        ['separable_conv2d_1[0][0]']     \n",
            " rmalization)                   28)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 56, None, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 56, None, 12  8320        ['activation_1[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 56, None, 12  0           ['max_pooling2d[0][0]',          \n",
            "                                8)                                'conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 56, None, 12  0           ['add[0][0]']                    \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_2 (SeparableC  (None, 56, None, 25  34176      ['activation_4[0][0]']           \n",
            " onv2D)                         6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 56, None, 25  1024       ['separable_conv2d_2[0][0]']     \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 56, None, 25  0           ['batch_normalization_4[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_3 (SeparableC  (None, 56, None, 25  68096      ['activation_5[0][0]']           \n",
            " onv2D)                         6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 56, None, 25  1024       ['separable_conv2d_3[0][0]']     \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 28, None, 25  0          ['batch_normalization_5[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 28, None, 25  33024       ['add[0][0]']                    \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 28, None, 25  0           ['max_pooling2d_1[0][0]',        \n",
            "                                6)                                'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 28, None, 25  0           ['add_1[0][0]']                  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_4 (SeparableC  (None, 28, None, 51  133888     ['activation_6[0][0]']           \n",
            " onv2D)                         2)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 28, None, 51  2048       ['separable_conv2d_4[0][0]']     \n",
            " rmalization)                   2)                                                                \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 28, None, 51  0           ['batch_normalization_6[0][0]']  \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_5 (SeparableC  (None, 28, None, 51  267264     ['activation_7[0][0]']           \n",
            " onv2D)                         2)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 28, None, 51  2048       ['separable_conv2d_5[0][0]']     \n",
            " rmalization)                   2)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 14, None, 51  0          ['batch_normalization_7[0][0]']  \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 14, None, 51  131584      ['add_1[0][0]']                  \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 14, None, 51  0           ['max_pooling2d_2[0][0]',        \n",
            "                                2)                                'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 14, None, 51  0           ['add_2[0][0]']                  \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_6 (SeparableC  (None, 14, None, 72  378072     ['activation_8[0][0]']           \n",
            " onv2D)                         8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 14, None, 72  2912       ['separable_conv2d_6[0][0]']     \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 14, None, 72  0           ['batch_normalization_8[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " separable_conv2d_7 (SeparableC  (None, 14, None, 72  537264     ['activation_9[0][0]']           \n",
            " onv2D)                         8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 14, None, 72  2912       ['separable_conv2d_7[0][0]']     \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 7, None, 728  0          ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 7, None, 728  373464      ['add_2[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 7, None, 728  0           ['max_pooling2d_3[0][0]',        \n",
            "                                )                                 'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " separable_conv2d_8 (SeparableC  (None, 7, None, 102  753048     ['add_3[0][0]']                  \n",
            " onv2D)                         4)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 7, None, 102  4096       ['separable_conv2d_8[0][0]']     \n",
            " ormalization)                  4)                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 7, None, 102  0           ['batch_normalization_10[0][0]'] \n",
            "                                4)                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1024)        0           ['activation_10[0][0]']          \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            1025        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,782,649\n",
            "Trainable params: 2,773,913\n",
            "Non-trainable params: 8,736\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##  Defining a CNN architecture ..\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Rescaling(1.0 / 255)(x)\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"softmax\"\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
        "model.summary()\n",
        "#keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nyc-kOe1VTKk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "ae06aa45-b7bc-45da-95e1-37f4fa7b808b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 16/293 [>.............................] - ETA: 7:17 - loss: 0.8735 - accuracy: 0.5352"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b04b06f85a3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Fitting the model on dataset ..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# models.save_model(model, filepath, overwrite=True, include_optimizer=True, save_format='h5', save_traces=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## Setting up epochs, callbacks and start the training ..\n",
        "epochs = 5\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),]    # Use '.keras' or 'h5' as format of model to be saved  ..\n",
        "\n",
        "# Compiling the model  ..\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"],)\n",
        "\n",
        "# Fitting the model on dataset ..\n",
        "model.fit(train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds, verbose=1, workers=8)\n",
        "# models.save_model(model, filepath, overwrite=True, include_optimizer=True, save_format='h5', save_traces=True)\n",
        "\n",
        "##  Running inference on a single image ..\n",
        "img = keras.preprocessing.image.load_img(\"PetImages/Cat/6779.jpg\", target_size=image_size)\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  \n",
        "\n",
        "## Making predictions from a model\n",
        "model = tf.keras.models.load_model('/content/save_at_5.keras')\n",
        "predictions = model.predict(img_array)\n",
        "score = predictions[0]\n",
        "if score <= 0.5:\n",
        "  print ('This is a cat')\n",
        "else:\n",
        "  print ('This is a Dog')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n"
      ],
      "metadata": {
        "id": "7sG_IQCJCVJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "rQmo_VeHHWDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg16.output)"
      ],
      "metadata": {
        "id": "ulwYIbIiCb15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "model = Model(inputs=vgg16.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "IEAp4UPvCfDx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}