{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eQgXgXqmVTKd"
   },
   "outputs": [],
   "source": [
    "##  Importing some modules\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tppYW3y-VTKe",
    "outputId": "46d2f689-cb10-4c91-8349-70f0b8b8e52f"
   },
   "source": [
    "##  Downloading the Cats-Dogs image dataset and unzip ..\n",
    "!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
    "!unzip -q kagglecatsanddogs_5340.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJcKQti2VTKg",
    "outputId": "871c2190-bfcd-47cb-c058-7edcffb92dce"
   },
   "source": [
    "##  filtering out some corrupted images\n",
    "num_skipped = 0\n",
    "for folder_name in (\"Cat\", \"Dog\"):\n",
    "    folder_path = os.path.join(\"PetImages\", folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # Delete corrupted image\n",
    "            os.remove(fpath)\n",
    "\n",
    "print(\"Deleted %d images\" % num_skipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7TALJ4QVTKh"
   },
   "source": [
    "## Generate a `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-5BrP27VTKh",
    "outputId": "bc94c2f9-7642-45d3-b417-4d8d32469d41"
   },
   "outputs": [],
   "source": [
    "##  Generating dataset ..\n",
    "\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\"PetImages\", validation_split=0.2, subset=\"training\", seed=1337, image_size=image_size, batch_size=batch_size,)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\"PetImages\", validation_split=0.2,  subset=\"validation\",  seed=1337, image_size=image_size, batch_size=batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "I4R7cHuUVTKh",
    "outputId": "fe4d03a9-5e9f-4105-dc37-bb91e1f3fd5d"
   },
   "outputs": [],
   "source": [
    "##  Visualizing some images from dataset ..\n",
    "# 0 - cat,  1 - Dog\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVBX_ODIVTKi"
   },
   "outputs": [],
   "source": [
    "##  Data augmentation \n",
    "\n",
    "data_augmentation = keras.Sequential([layers.RandomFlip(\"horizontal\"), \n",
    "                                      layers.RandomRotation(0.1),\n",
    "                                      layers.RandomBrightness(0.3),\n",
    "                                      layers.RandomContrast(0.4),\n",
    "                                      layers.RandomWidth(0.2)])\n",
    "                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTRoX8C-VTKi"
   },
   "source": [
    "Let's visualize what the augmented samples look like, by applying `data_augmentation`\n",
    "repeatedly to the first image in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VX73gC1VTKi"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLRxgG5MVTKi"
   },
   "source": [
    "## Standardizing the data\n",
    "\n",
    "Our image are already in a standard size (180x180), as they are being yielded as\n",
    "contiguous `float32` batches by our dataset. However, their RGB channel values are in\n",
    "the `[0, 255]` range. This is not ideal for a neural network;\n",
    "in general you should seek to make your input values small. Here, we will\n",
    "standardize values to be in the `[0, 1]` by using a `Rescaling` layer at the start of\n",
    "our model.\n",
    "\n",
    "## Two options to preprocess the data\n",
    "\n",
    "There are two ways you could be using the `data_augmentation` preprocessor:\n",
    "\n",
    "**Option 1: Make it part of the model**, like this:\n",
    "\n",
    "```python\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "...  # Rest of the model\n",
    "```\n",
    "\n",
    "With this option, your data augmentation will happen *on device*, synchronously\n",
    "with the rest of the model execution, meaning that it will benefit from GPU\n",
    "acceleration.\n",
    "\n",
    "Note that data augmentation is inactive at test time, so the input samples will only be\n",
    "augmented during `fit()`, not when calling `evaluate()` or `predict()`.\n",
    "\n",
    "If you're training on GPU, this may be a good option.\n",
    "\n",
    "**Option 2: apply it to the dataset**, so as to obtain a dataset that yields batches of\n",
    "augmented images, like this:\n",
    "\n",
    "```python\n",
    "augmented_train_ds = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y))\n",
    "```\n",
    "\n",
    "With this option, your data augmentation will happen **on CPU**, asynchronously, and will\n",
    "be buffered before going into the model.\n",
    "\n",
    "If you're training on CPU, this is the better option, since it makes data augmentation\n",
    "asynchronous and non-blocking.\n",
    "\n",
    "In our case, we'll go with the second option. If you're not sure\n",
    "which one to pick, this second option (asynchronous preprocessing) is always a solid choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pf4caOY0VTKj"
   },
   "outputs": [],
   "source": [
    "## Configure the dataset for performance\n",
    "# Let's make sure to use buffered prefetching so we can yield data from disk without having I/O becoming blocking ..\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=64)\n",
    "val_ds = val_ds.prefetch(buffer_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dwopxm0vVTKj"
   },
   "source": [
    "## Build a model\n",
    "\n",
    "We'll build a small version of the Xception network. We haven't particularly tried to\n",
    "optimize the architecture; if you want to do a systematic search for the best model\n",
    " configuration, consider using\n",
    "[KerasTuner](https://github.com/keras-team/keras-tuner).\n",
    "\n",
    "Note that:\n",
    "\n",
    "- We start the model with the `data_augmentation` preprocessor, followed by a\n",
    " `Rescaling` layer.\n",
    "- We include a `Dropout` layer before the final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bJ_TCeXVTKj",
    "outputId": "8ed8e5d1-6c60-4218-8508-693f2310ac9d"
   },
   "outputs": [],
   "source": [
    "##  Defining a CNN architecture ..\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "model.summary()\n",
    "#keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "Nyc-kOe1VTKk",
    "outputId": "ae06aa45-b7bc-45da-95e1-37f4fa7b808b"
   },
   "outputs": [],
   "source": [
    "## Setting up epochs, callbacks and start the training ..\n",
    "epochs = 5\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),]    # Use '.keras' or 'h5' as format of model to be saved  ..\n",
    "\n",
    "# Compiling the model  ..\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"],)\n",
    "\n",
    "# Fitting the model on dataset ..\n",
    "model.fit(train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds, verbose=1, workers=8)\n",
    "# models.save_model(model, filepath, overwrite=True, include_optimizer=True, save_format='h5', save_traces=True)\n",
    "\n",
    "##  Running inference on a single image ..\n",
    "img = keras.preprocessing.image.load_img(\"PetImages/Cat/6779.jpg\", target_size=image_size)\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  \n",
    "\n",
    "## Making predictions from a model\n",
    "model = tf.keras.models.load_model('/content/save_at_5.keras')\n",
    "predictions = model.predict(img_array)\n",
    "score = predictions[0]\n",
    "if score <= 0.5:\n",
    "  print ('This is a cat')\n",
    "else:\n",
    "  print ('This is a Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sG_IQCJCVJx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQmo_VeHHWDB"
   },
   "outputs": [],
   "source": [
    "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulwYIbIiCb15"
   },
   "outputs": [],
   "source": [
    "x = Flatten()(vgg16.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEAp4UPvCfDx"
   },
   "outputs": [],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "model = Model(inputs=vgg16.input, outputs=prediction)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
